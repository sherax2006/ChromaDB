{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ChromaDB** is Open Source Vector Database helps users to store their documents in vector form and retrieve relevent documents from Vector DB based on user's query efficiently.\n",
        "ChromaDB uses Cosine Matrix by default to findout Similarity in query and documents stored in collections."
      ],
      "metadata": {
        "id": "J4PfRDr4Opzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common Distance Metrics for Multimodal Use Cases.**\n",
        "\n",
        "**01: Cosine Distance (1 - Cosine Similarity)**\n",
        "      Best For Images, Audio and Texts\n",
        "\n",
        "**02: L2 Distance (Euclidean)**\n",
        "      Best for Spatial data, High dimensional embeddings\n",
        "      Uses whenabsilute magnitude matters\n",
        "\n",
        "**03: Inner Product (IP)**\n",
        "      Best for Ranking Based Retrieval\n",
        "      When using dot-product-based models (e.g., CLIP with max similarity search)"
      ],
      "metadata": {
        "id": "nzDmO1QxR5hq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-RSsMmzb-Pn3"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n"
      ],
      "metadata": {
        "id": "uE5aCbOWJEoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chroma DB Client**"
      ],
      "metadata": {
        "id": "856u01CJ_lE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chroma Clients**\n",
        "\n",
        "Ephemeral Client\n",
        "\n",
        "Persistent Client\n",
        "\n",
        "Client-Server Mode\n",
        "\n",
        "Python Http-Only Client"
      ],
      "metadata": {
        "id": "QhjYi0yAVQ-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chromadb\n",
        "chroma_client = chromadb.Client() # Ephemeral Client\n"
      ],
      "metadata": {
        "id": "k9HRclkd-Vk6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Collection**"
      ],
      "metadata": {
        "id": "7ajGqilz_rKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "collection = chroma_client.get_or_create_collection(name=\"RAG_Application\")\n"
      ],
      "metadata": {
        "id": "xRVmHzLH_uDv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Add External Resources to VectorDB (Chroma DB)**"
      ],
      "metadata": {
        "id": "y_nx7vOM_82A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# switch `add` to `upsert` to avoid adding the same documents every time\n",
        "collection.upsert(\n",
        "    documents=[\n",
        "        \"This is a document about pineapple\",\n",
        "        \"This is a document about oranges\",\n",
        "        \"My name is M Sheraz Rana and I am 25 years old. I am working on Learning Generative AI development.\"\n",
        "    ],\n",
        "    ids=[\"id1\", \"id2\",\"id3\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "dKMzQCauAIS4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d588a839-ef93-422b-a257-7784a61e73ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:01<00:00, 43.3MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding Extra Documents From Extrernal Resources**"
      ],
      "metadata": {
        "id": "04U5iGikRmxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming each document in the .txt file is separated by a newline\n",
        "file_path = \"/content/PersonalData.txt\"  # Path to your .txt file\n",
        "\n",
        "# Open and read the file\n",
        "with open(file_path, \"r\") as file:\n",
        "    documents = file.readlines()  # Read all lines in the file\n",
        "\n",
        "# Strip any extra whitespace characters like newlines\n",
        "documents = [doc.strip() for doc in documents]\n",
        "\n",
        "# Generate unique ids (or you can assign custom ids)\n",
        "ids = [f\"id{i+1}\" for i in range(len(documents))]\n",
        "\n",
        "# Use the upsert method with the read documents\n",
        "collection.upsert(\n",
        "    documents=documents,\n",
        "    ids=ids\n",
        ")\n"
      ],
      "metadata": {
        "id": "20CJIwv9QaAJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, Getting Query and get result from DB**"
      ],
      "metadata": {
        "id": "o8BdThg_AMHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "user_query = \"what am I?\"\n",
        "response = collection.query(\n",
        "    query_texts=user_query, # Chroma will embed this for you\n",
        "    n_results=2 # how many results to return\n",
        ")\n",
        "\n",
        "retrieved_documents = response[\"documents\"][0]\n",
        "retrieved_documents\n",
        "context = \"\\n\".join(retrieved_documents)\n",
        "final_promp = f\"Context:\\n{context}\\n\\nUser Query: {user_query}\\n Answer:\"\n",
        "print(final_promp)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4_uLqTbAP2H",
        "outputId": "1a701b30-ebe1-4c23-9059-db44078e78ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context:\n",
            "My name is M Sheraz Rana and I am 25 years old. I am working on Learning Generative AI development.\n",
            "This is a document about pineapple\n",
            "\n",
            "User Query: what am I?\n",
            " Answer:\n",
            "{'ids': [['id3', 'id1']], 'embeddings': None, 'documents': [['My name is M Sheraz Rana and I am 25 years old. I am working on Learning Generative AI development.', 'This is a document about pineapple']], 'uris': None, 'data': None, 'metadatas': [[None, None]], 'distances': [[1.7218676805496216, 1.7450346946716309]], 'included': [<IncludeEnum.distances: 'distances'>, <IncludeEnum.documents: 'documents'>, <IncludeEnum.metadatas: 'metadatas'>]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now, Using LLM And observing Response fro it**"
      ],
      "metadata": {
        "id": "hxswzn_CIltY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "key = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=key)\n",
        "\n",
        "# Create the model\n",
        "generation_config = {\n",
        "  \"temperature\": 1.25,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 40,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "  model_name=\"gemini-2.0-flash-exp\",\n",
        "  generation_config=generation_config,\n",
        ")\n",
        "\n",
        "chat_session = model.start_chat(\n",
        "  history=[\n",
        "  ]\n",
        ")\n",
        "\n",
        "response = chat_session.send_message(final_promp)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "KeH0NsR7MXCh",
        "outputId": "b80c99e3-c986-4f9b-d334-2535b1e0295f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are M Sheraz Rana, a 25-year-old who is currently learning generative AI development.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}